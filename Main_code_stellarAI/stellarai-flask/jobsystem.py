# -*- coding: utf-8 -*-
"""JobSystem.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14GYiMnOsy4wTqfgeAfabVoC06lJCTK0P

# Recomendation Engine
"""

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from nltk.tokenize import TreebankWordTokenizer
from nltk.stem import PorterStemmer
from sklearn.decomposition import TruncatedSVD, NMF
import re
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.metrics import accuracy_score
import pickle
import PyPDF2
import json
df = pd.read_csv('jobs_stellarai.csv')

def display_topics(model, feature_names, no_top_words, topic_names=None):
  topic_list = []
  for i, topic in enumerate(model.components_):
    topic_list.append(", ".join([feature_names[k] for k in topic.argsort()[:-no_top_words - 1:-1]]))
  return model.components_, topic_list

def tokenize_stem(series):
  tokenizer = TreebankWordTokenizer()
  stemmer = PorterStemmer()
  series = series.apply(lambda x: x.replace("\n", ' '))
  series = series.apply(lambda x: tokenizer.tokenize(x))
  series = series.apply(lambda x: [stemmer.stem(w) for w in x])
  series = series.apply(lambda x: ' '.join(x))
  return series

df['Job Description']= tokenize_stem(df['Job Description'])


def return_topics(series, num_topics, no_top_words, model, vectorizer):
  series=tokenize_stem(series)
  ex_label = [e[:30]+"..." for e in series]
  vec = vectorizer(stop_words='english')
  doc_word = vec.fit_transform(series) #vectorizes series

  def_model = model(num_topics)
  def_model = def_model.fit(doc_word)
  doc_topic = def_model.transform(doc_word)
  model_components, topic_list = display_topics(def_model, vec.get_feature_names_out(), no_top_words)
  return def_model.components_, doc_topic, def_model, vec, topic_list

def process_data():
  df =  pd.read_csv('jobs_stellarai.csv')
  jobs_df = pd.DataFrame(zip(df['Job Description'], df['keyword']), columns=['Description', 'Job'])

  array, doc, topic_model, vec, topic_list = return_topics(jobs_df['Description'], 20, 10, TruncatedSVD, TfidfVectorizer)
  topic_df = pd.DataFrame(doc)
  topic_df.columns = ['Topic ' + str(i+1) for i in range(len(topic_df.columns))] #Making the data frame look *sexy*

  topic_df['jobs'] = jobs_df.Job
  return topic_df, topic_model, vec, topic_list

def predictive_modeling(df):
  X,Y = df.iloc[:,0:-1], df.iloc[:,-1] #split data frame for training, X->data, Y-> classes
  X_tr, X_te, Y_tr, Y_te = train_test_split(X, Y)

  rand_forest = RandomForestClassifier(n_estimators=500, max_depth=9)
  rand_forest.fit(X_tr, Y_tr)
  return rand_forest

def get_topic_class_model():
  jobs_df, model, vec, topic_list = process_data()
  model_1 = predictive_modeling(jobs_df)
  return model, model_1, vec

def resume_pred(topic_model, model, resume):
  doc = topic_model.transform(resume)
  return model.predict_proba(doc), model.classes_

def main(resume, topic_model, model, vec):
  doc = tokenize_stem(resume)
  doc = vec.transform(doc)
  prob, classes = resume_pred(topic_model, model, doc)
  return classes, prob[0]*100

def turn_json(classes, prob):
  result_dict = {}
  for i in range(len(classes)):
    c = classes[i]
    c = c.replace(",", " ")
    c = c.title()
    result_dict[c] = round(prob[i],2)
  return result_dict

def main_(resume):
  topic_model, model, vec = get_topic_class_model()
  doc = tokenize_stem(resume)
  doc = vec.transform(doc)
  prob, classes = resume_pred(topic_model, model, doc)
  return turn_json(classes, prob[0]*100)


def main_res(resume_file):
  pdfFile = open(resume_file+'.pdf', 'rb')
  pdfReader = PyPDF2.PdfFileReader(pdfFile)
  user_input = ''
  for i in range(pdfReader.numPages):
    curr_page = pdfReader.getPage(i)
    user_input += curr_page.extract_text()

  pdfFile.close()
  user_input = pd.Series(user_input)
  pred = main_(user_input)

  with open(resume_file+'.json', 'w') as outfile:
    json.dump(pred, outfile)
  return pred
